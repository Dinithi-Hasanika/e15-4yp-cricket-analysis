# -*- coding: utf-8 -*-
"""Batsmen_Carrear_Features.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TwJOmHzBBQgF7v8c32sS-wfsDrNhUa2B
"""

from google.colab import auth
auth.authenticate_user()
import gspread
from oauth2client.client import GoogleCredentials
gc = gspread.authorize(GoogleCredentials.get_application_default())

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

wb = gc.open_by_url('https://docs.google.com/spreadsheets/d/1peLpNFoEu8NHtVPttJXz4-aScixYu5dh_-6gYPOi9rQ/edit#gid=670066504')

sheet = wb.worksheet('bt_data')

data = sheet.get_all_values()

df = pd.DataFrame(data)
df.columns = df.iloc[0]
df = df.iloc[1:]

df.head()

import sklearn
print(sklearn.__version__)

from sklearn.linear_model import LinearRegression
from matplotlib import pyplot

print(df.info())

df["Mat"]= df["Mat"].astype(float)
df["Inns"]= df["Inns"].astype(float)
df["NO"]= df["NO"].astype(float)
df["HS_NO"]= df["HS_NO"].astype(float)
df["Ave"]= df["Ave"].astype(float)
df["BF"]= df["BF"].astype(float)
df["SR"]= df["SR"].astype(float)
df["100"]= df["100"].astype(float)
df["50"]= df["50"].astype(float)
df["0"]= df["0"].astype(float)
df["Last 4 match runs mean"]= df["Last 4 match runs mean"].astype(float)
df["Man of the match"]= df["Man of the match"].astype(float)
df["Runs"]= df["Runs"].astype(float)
df["HS"]= df["HS"].astype(float)
df["Height (cm)"]= df["Height (cm)"].astype(float)
df["Batsmen Score"]= df["Batsmen Score"].astype(float)

print(df.info())

from sklearn.preprocessing import LabelEncoder

label = LabelEncoder()
df['Batting Style'] = label.fit_transform(df['Batting Style'])

df.head()

from sklearn.ensemble import RandomForestClassifier

carrear_feature_names = ["Man of the match", "Last 4 match runs mean", "Height (cm)", "Batting Style", "Ave", "NO", "HS", "HS_NO", "SR", "100", "50", "0"]
X_carrear = df[carrear_feature_names]
Y = df["Runs"]

#split the data set as training set and test set randomly
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X_carrear, Y, random_state=0)

#apply scaling
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

"""Linear Regression Carrear Features"""

modelc_lreg = LinearRegression()

modelc_lreg.fit(X_train, y_train)

importance_lreg = modelc_lreg.coef_

for i,v in enumerate(importance_lreg):
	print('Feature:%0d -> %s, Score: %.5f' % (i,carrear_feature_names[i],v))

pyplot.bar([x for x in range(len(importance_lreg))], importance_lreg)
pyplot.xticks(np.arange(len(carrear_feature_names)), carrear_feature_names,rotation='vertical')
pyplot.show()

print('Accuracy of Linear regression classifier on training set: {:.2f}'
     .format(modelc_lreg.score(X_train, y_train)))
print('Accuracy of Linear regression classifier on test set: {:.2f}'
     .format(modelc_lreg.score(X_test, y_test)))

"""Random Forest Carrear features"""

modelrfc = RandomForestClassifier()
modelrfc.fit(X_train, y_train)

importancerfc = modelrfc.feature_importances_

for i,v in enumerate(importancerfc):
	print('Feature:%0d -> %s, Score: %.5f' % (i,carrear_feature_names[i],v))

pyplot.bar([x for x in range(len(importancerfc))], importancerfc)
pyplot.xticks(np.arange(len(carrear_feature_names)), carrear_feature_names,rotation='vertical')
pyplot.show()

print('Accuracy of Linear regression classifier on training set: {:.2f}'
     .format(modelrfc.score(X_train, y_train)))
print('Accuracy of Linear regression classifier on test set: {:.2f}'
     .format(modelrfc.score(X_test, y_test)))

"""Xgboost Carrear Features"""

from xgboost import XGBRegressor
# define the model
modelxg = XGBRegressor()
# fit the model
modelxg.fit(X_train, y_train)
# get importance
importancexg = modelxg.feature_importances_
# summarize feature importance
for i,v in enumerate(importancexg):
	print('Feature: %0d, -> %s Score: %.5f' % (i,carrear_feature_names[i] ,v))
# plot feature importance
plt.bar([x for x in range(len(importancexg))], importancexg)
pyplot.xticks(np.arange(len(carrear_feature_names)), carrear_feature_names,rotation='vertical')
plt.show()

print('Accuracy of xgboost classifier on training set: {:.2f}'
     .format(modelxg.score(X_train, y_train)))
print('Accuracy of xgboost classifier on test set: {:.2f}'
     .format(modelxg.score(X_test, y_test)))

"""Permutation Carrear Features"""

from sklearn.neighbors import KNeighborsRegressor
from sklearn.inspection import permutation_importance

# define the model
knn = KNeighborsRegressor()
# fit the model
knn.fit(X_train, y_train)
# perform permutation importance
results = permutation_importance(knn, X_train, y_train, scoring='neg_mean_squared_error')
# get importance
importance_k = results.importances_mean
# summarize feature importance
for i,v in enumerate(importance_k):
	print('Feature: %0d, -> %s Score: %.5f' % (i,carrear_feature_names[i],v))
# plot feature importance
plt.bar([x for x in range(len(importance_k))], importance_k)
pyplot.xticks(np.arange(len(carrear_feature_names)), carrear_feature_names,rotation='vertical')
plt.show()

print('Accuracy of knn classifier on training set: {:.2f}'
     .format(knn.score(X_train, y_train)))
print('Accuracy of knn classifier on test set: {:.2f}'
     .format(knn.score(X_test, y_test)))

"""CART carrear features"""

from sklearn.tree import DecisionTreeRegressor
# from matplotlib import pyplot

# define the model
modelcart = DecisionTreeRegressor()
# fit the model
modelcart.fit(X_train, y_train)
# get importance
importancecart = modelcart.feature_importances_
# summarize feature importance
for i,v in enumerate(importancecart):
	print('Feature: %0d,-> %s Score: %.5f' % (i,carrear_feature_names[i],v))
# plot feature importance
pyplot.bar([x for x in range(len(importancecart))], importancecart)
pyplot.xticks(np.arange(len(carrear_feature_names)), carrear_feature_names,rotation='vertical')
pyplot.show()

print('Accuracy of cart classifier on training set: {:.2f}'
     .format(modelcart.score(X_train, y_train)))
print('Accuracy of cart classifier on test set: {:.2f}'
     .format(modelcart.score(X_test, y_test)))