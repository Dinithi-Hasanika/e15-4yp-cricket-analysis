# -*- coding: utf-8 -*-
"""CO421-visual.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1G1XuX_FagVAs6hhjTbrXTJ-AIKijc832
"""

from google.colab import auth
auth.authenticate_user()
import gspread
from oauth2client.client import GoogleCredentials
gc = gspread.authorize(GoogleCredentials.get_application_default())

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

wb = gc.open_by_url('https://docs.google.com/spreadsheets/d/1peLpNFoEu8NHtVPttJXz4-aScixYu5dh_-6gYPOi9rQ/edit#gid=670066504')

sheet = wb.worksheet('bt_data')

data = sheet.get_all_values()

df = pd.DataFrame(data)
df.columns = df.iloc[0]
df = df.iloc[1:]

df.head()

del df["u"]
del df["v"]
del df["w"]
del df["Career score temp"]
del df["Recent score temp"]
del df["Max caree score"]
del df["Max recent sore"]
del df["Career Score"]
del df["Recent Score"]
del df["Batsmen Score"]

print ("Dataset Length: ", len(df))
print ("Dataset Shape: ", df.shape)

df["Height (cm)"]= df["Height (cm)"].astype(float)
df["Mat"]= df["Mat"].astype(float)
df["Inns"]= df["Inns"].astype(float)
df["NO"]= df["NO"].astype(float)
df["HS_NO"]= df["HS_NO"].astype(float)
df["Ave"]= df["Ave"].astype(float)
df["BF"]= df["BF"].astype(float)
df["SR"]= df["SR"].astype(float)
df["100"]= df["100"].astype(float)
df["50"]= df["50"].astype(float)
df["0"]= df["0"].astype(float)
df["Last 4 match runs mean"]= df["Last 4 match runs mean"].astype(float)
df["Man of the match"]= df["Man of the match"].astype(float)
df["Runs"]= df["Runs"].astype(float)
df["HS"]= df["HS"].astype(float)

df.dtypes

df["Batting Style"].replace('R',1, inplace=True)
df["Batting Style"].replace('L',0, inplace=True)
df["Batting Style"]= df["Batting Style"].astype(int)

from pandas.plotting import scatter_matrix
sm = scatter_matrix(df, alpha=0.2, figsize=(12, 12), diagonal='kde')

#Change label rotation
[s.xaxis.label.set_rotation(90) for s in sm.reshape(-1)]
[s.yaxis.label.set_rotation(0) for s in sm.reshape(-1)]

#May need to offset label when rotating to prevent overlap of figure
[s.get_yaxis().set_label_coords(-1.5,0.5) for s in sm.reshape(-1)]

#Hide all ticks
[s.set_xticks(()) for s in sm.reshape(-1)]
[s.set_yticks(()) for s in sm.reshape(-1)]
plt.show()

"""**Runs vs. Other features**"""

feature_names = ['Man of the match','Last 4 match runs mean','Height (cm)','Batting Style','Mat','Inns','NO','HS','HS_NO','BF','SR','100','50','0']
X = df[feature_names]
Y = df['Runs']

"""*Xgboost*"""

from xgboost import XGBRegressor
# define the model
model = XGBRegressor()
# fit the model
model.fit(X, Y)
# get importance
importance = model.feature_importances_
# summarize feature importance
for i,v in enumerate(importance):
	print('Feature: %0d, -> %s Score: %.5f' % (i,feature_names[i] ,v))
# plot feature importance
plt.bar([x for x in range(len(importance))], importance)
plt.show()

"""*Permutation*"""

from sklearn.neighbors import KNeighborsRegressor
from sklearn.inspection import permutation_importance

# define the model
knn = KNeighborsRegressor()
# fit the model
knn.fit(X, Y)
# perform permutation importance
results = permutation_importance(model, X, Y, scoring='neg_mean_squared_error')
# get importance
importance_k = results.importances_mean
# summarize feature importance
for i,v in enumerate(importance_k):
	print('Feature: %0d, -> %s Score: %.5f' % (i,feature_names[i],v))
# plot feature importance
plt.bar([x for x in range(len(importance_k))], importance_k)
plt.show()

"""*Linear regression*"""

from sklearn.linear_model import LinearRegression
from matplotlib import pyplot

model = LinearRegression()

model.fit(X, Y)

importance = model.coef_

for i,v in enumerate(importance):
	print('Feature:%0d -> %s, Score: %.5f' % (i,feature_names[i],v))

pyplot.bar([x for x in range(len(importance))], importance)
pyplot.show()

"""**CART Regression Feature Importance**"""

from sklearn.tree import DecisionTreeRegressor
# from matplotlib import pyplot

# define the model
model = DecisionTreeRegressor()
# fit the model
model.fit(X, Y)
# get importance
importance = model.feature_importances_
# summarize feature importance
for i,v in enumerate(importance):
	print('Feature: %0d, Score: %.5f' % (i,v))
# plot feature importance
pyplot.bar([x for x in range(len(importance))], importance)
pyplot.xticks(np.arange(len(feature_names)), feature_names,rotation='vertical')
pyplot.show()

#split the data set as training set and test set randomly
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=0)

#apply scaling
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

model_reg = LinearRegression()
model_reg.fit(X_train, y_train)

importance1 = model_reg.coef_
for i,v in enumerate(importance1):
	print('Feature:%0d -> %s, Score: %.5f' % (i,feature_names[i],v))

pyplot.bar([x for x in range(len(importance1))], importance1)
pyplot.show()

print('Accuracy of Linear regression classifier on training set: {:.2f}'
     .format(model_reg.score(X_train, y_train)))
print('Accuracy of Linear regression classifier on test set: {:.2f}'
     .format(model_reg.score(X_test, y_test)))

model_dt = DecisionTreeRegressor()
model_dt.fit(X_train, y_train)

importance_dt = model_dt.feature_importances_
# summarize feature importance
for i,v in enumerate(importance_dt):
	print('Feature: %0d, Score: %.5f' % (i,v))
# plot feature importance
pyplot.bar([x for x in range(len(importance_dt))], importance_dt)
pyplot.xticks(np.arange(len(feature_names)), feature_names,rotation='vertical')
pyplot.show()

print('Accuracy of DecisionTree Regressor on training set: {:.2f}'
     .format(model_dt.score(X_train, y_train)))
print('Accuracy of DecisionTree Regressor on test set: {:.2f}'
     .format(model_dt.score(X_test, y_test)))

"""*Xgboost accuracy*"""

xgb_reg = XGBRegressor()
xgb_reg.fit(X_train, y_train)

xgb_importance = xgb_reg.feature_importances_
for i,v in enumerate(xgb_importance):
	print('Feature:%0d -> %s, Score: %.5f' % (i,feature_names[i],v))

# plot feature importance
pyplot.bar([x for x in range(len(xgb_importance))], xgb_importance)
pyplot.show()

print('Accuracy of Xgboost regressor on training set: {:.2f}'
     .format(xgb_reg.score(X_train, y_train)))
print('Accuracy of Xgboost regressor on test set: {:.2f}'
     .format(xgb_reg.score(X_test, y_test)))

"""*Permutation Accuracy*"""

knn_reg = KNeighborsRegressor()
knn_reg.fit(X_train, y_train)

# perform permutation importance
resultsk = permutation_importance(knn_reg, X_train, y_train, scoring='neg_mean_squared_error')


perm_importance = resultsk.importances_mean
for i,v in enumerate(perm_importance):
	print('Feature:%0d -> %s, Score: %.5f' % (i,feature_names[i],v))

# plot feature importance
pyplot.bar([x for x in range(len(perm_importance))], perm_importance)
pyplot.xticks(np.arange(len(feature_names)), feature_names,rotation='vertical')
pyplot.show()

print('Accuracy of knn regressor on training set: {:.2f}'
     .format(knn_reg.score(X_train, y_train)))
print('Accuracy of knn regressor on test set: {:.2f}'
     .format(knn_reg.score(X_test, y_test)))

"""Random Forest"""

from sklearn.ensemble import RandomForestClassifier
modelrf = RandomForestClassifier()
modelrf.fit(X_train, y_train)

importance3 = modelrf.feature_importances_

for i,v in enumerate(importance3):
	print('Feature:%0d -> %s, Score: %.5f' % (i,feature_names[i],v))

pyplot.bar([x for x in range(len(importance3))], importance3)
pyplot.xticks(np.arange(len(feature_names)), feature_names,rotation='vertical')
pyplot.show()

print('Accuracy of Random forest classifier on training set: {:.2f}'
     .format(modelrf.score(X_train, y_train)))
print('Accuracy of Random forest classifier on test set: {:.2f}'
     .format(modelrf.score(X_test, y_test)))

"""**Batsmen Score Vs Other Features**"""

df1 = pd.DataFrame(data)
df1.columns = df1.iloc[0]
df1 = df1.iloc[1:]



feature_names1 =["Man of the match","Last 4 match runs mean","Height (cm)","Batting Style","Mat","Inns","NO","Runs","HS","HS_NO","Ave","BF","SR","100","50","0"]
X1 = df[feature_names1]
Y1 = df["Batsmen Score"]

"""*Decision Tree Regression*"""

